It is well known that human learn by stepwise (Markovian) learning (or optimization) \cite{}, but sometimes, when stuck, they tend to reset their beliefs \cite{}. This reset is usually considered as a random move performed, in order to explore yet unknown portions of the problem space \cite{}. Here, we show a more subtle view, with a continuum between Markovian learning and sharp exploration. Furthermore, random exploration is actually not completely random, but rather involves a recombination of solutions explored much further in the past. 