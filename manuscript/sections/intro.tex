\section{Introduction}
From financial stability to the stability of democracies, beliefs play a central role in our explanation of many phenomena. In the social sciences, these beliefs are often conceptualized as probabilistic assessments over states of the world.  However, they are derived from coherent belief systems people hold in their minds regarding how the world works as supported by recent work in cognitive science \cite{lombrozo2006structure, anderson1990cognitive}.  How do humans learn in simple and in complex systems?  How efficiently do they explore the space of possible beliefs and how closely is the direction of exploration tied to experience?  

Our work presents new experimental results on the rate at which people learn in more or less complex environments. We find that the rate of learning is much slower than it would be if learners were Bayesians as had been proposed in older economic theories \cite{Boyer84, Prescott72, Rothschild74, McLennan84, Mirman84, Easley89, Kiefer89}.

 Surprisingly, we found that the learning rate is identical when people build models about more or less complex systems, although accuracy is always higher when the system is structurally simpler (because initial models are better). We then propose a theoretical framework to explain the consistently slow rates of learning.  The problem seems to be linked to the well documented fact that humans are unable to generate truly random signals; they are pattern creators and pattern synthesizers.  Once they have explored regions of the space that they seek to learn something about, they tend to return to past patterns and construct mental combinations of different patterns that they have already explored in the past and it seems to be harder and harder as time goes on for humans to explore new regions in the space that they have not already visited before.

For some time now, cognitive scientists have posed that modeling people's beliefs about causation in the material world provides an effective explanatory framework for how we process information and learn from these observations \cite{Griffiths2008}.  Bayes Nets are well-defined mathematical objects that are easy to manipulate, do inference with and to compare different beliefs and they lend themselves to intuitive graphical representations.  The kinds of Bayes Nets that have been allowed for in experimental settings up to this point, however, have been extremely simplistic and there has been an unanswered call for learning experiments with increased complexity (Griffiths?).  Our work is to our knowledge the first answer to this call.  

The data used in this work come from an experiment that we ran using an innovative experimental platform designed to measure how participants form and update causal beliefs in more or less complex settings.  In the experiment, participants see a data stream: data about multiple binary variables in a system, which take on the value High or Low. For example, one variable could be a stock price and there may be a number of variables that explain its variation or are explained by its variation in turn.  A visual interface allows the subjects to draw a causal model of the system. The platform then computes predictions on the basis of the participant's causal model and makes those prediction visible to the participant. The participant then makes bets using these predictions. In doing so, the participant gets feedback on the accuracy of her beliefs, and can update her beliefs by modifying the causal model. The platform thus allows us to observe beliefs and learning in a very precise and controlled way.

As can be seen in Figure \ref{fig:xx} the distance between a person's evolving belief system about some physical system and the long-run absorbing distribution, which we interpret as a performance score, decays with time in a very specific way:

\begin{equation}
\label{ }
d(belief_{i, t}, absorbing distribution) = \alpha*t^{-\beta_i}
\end{equation}



The functional form of human learning in the context of our experiment, then, is the same as for the Bayesian learner (the red line in the figure), but the decay rate, $\beta$, of a human learner is much smaller than that of a Bayesian. 
\vspace{1cm}
\begin{figure}[h]
\label{xx}
\centerline{\epsfig{figure=../figures/histogram.eps,angle=0,width=14cm,scale=1}}
\caption{The average distance, as measured by the Jensen Shannon Divergence, between a person's model and the distribution from which the observations are drawn on which all models are based.}
\label{figure1}
\end{figure}

