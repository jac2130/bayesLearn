\section{Introduction}
In scientific research \cite{hisano2013challenges}, software engineering and cybersecurity \cite{littlewood1989predicting,maillart2017given}, politics \cite{clinton2014hard}, and daily life \cite{gerson1986hard}, individuals face problems that involve many interdependent variables and large problem spaces \cite{koller09, Pearl2009CMR}.These problems are known to be hard to humans and have been studied as such by cognitive scientists. Baysian Networks are used as models for human causal inference and resoning \cite{bramley2015staying, castnerForthcoming, Griffiths2008, Pearl88, Spiegler2016, spiegler2015}. Not only are these problems hard to humans, but they are also hard to computers, as most inferences in Probabilistic Graphical Models (of which Bayes Nets are a part) are NP hard \cite{koller09}. This difficulty explains diversity of modfels and is sometimes resolvable through ensembles and forms of model averaging.\\ 

Modern theories of cognition often start with the premise that the brain is in large part an inference engine \cite{Tenenbaum06theory-basedbayesian} and causal cognition is theorized as the construction of complex causal theories from extremely sparse observations. In this literature, simple experiments were designed to probe cognitive capabilities \cite{tenenbaum2001structure}. The conclusion that emerges is that the brain cannot simply be an information processor; the information is too sparse to spell out obvious theories and the theories are often better than what the observations alone can account for \cite{ortoleva2012modeling, Hong04} \\

{\bf However, there is a dearth of knowledge ....[to be completed]}\\

{\bf [this could be the dearth of knowledge ? : ]} Currently, it is poorly understood how cognitive exploration brings new understanding, which is then recombined with previously acquired knowledge, stored in memory (see Figure \ref{fig:2}A). Exploration occurs by leveraging memory (see Figure \ref{fig:2}B). While exploration entails a component of chance (beyond the previous cognitive frontier), recombination can be optimised to find the best possible recombination, which corresponds to the optimal proposed solution (i.e., as close as possible from the true solution) within the cognitive frontier.\\

Here, we investigate the fine-grained cognitive mechanisms of complex problem resolution, which involves 2 treatments {\bf for} the resolution of 3-node and 4-node Bayesian networks over one trial of 30 minutes, with a warm-up period of 10 minutes. Reverse-engineering these Bayesian networks involves evaluating respectively 8 and 16 joint probabilities (each between $0$ and $1$, normalized such that they all add up to $1$). Any change to any of these probabilities is registered with a resolution of one second [see Supplementary Information (SI) \ref{SI_experiment}].\\

Participants are incentivized .... {\bf [to be completed]}\\

The experiment we performed here is more complex than is typical in this literature in the following ways : participants are given monetary incentives for the truthful revelation and cognitively demanding refinements of their beliefs in a way that is common only in experimental economics.  In that way, the experiment is a bridge between experimental cognitive science and a new economics of cognition that is influenced by both, computer science and cognitive science \cite{Spiegler2016}. Important to this new literature is the explicit theoretical recognition of the seemingly obvious fact that information is not necessarily interpreted in the same way, even if all individuals are privy to the same exact information and only to that common information. The experiment from which our data stems, then, belongs to a literature that is situated in the convergence between Herbert Simon's classic theory of ``bounded rationality'' in economics \cite{Gigerenzer2001, Rubinstein98, tsang2008computational, simon1955behavioral} and modern theories of intelligence that are derived from attempts to engineer intelligence.\\  

{\bf [note sure what to do with this: ]} The complexity and the uncertainties of the information environment leave a lot to interpretation and it seems clear that these differences in interpretation--including purposeful manipulation of these interpretations by others--account for much more opinion heterogeneities in most human affairs than the differences in information exposure.  Most information is public information, available to all.\\

{\bf [note sure what to do with this: ]} Because we have discrete variables that are dependent on one another in discrete data structures, albeit parameterized with continuous valued parameters, landscapes are piece-wise smooth with discrete discontinuities and solutions cannot be reached by optimization strategies that rely on global continuity. {\bf $\rightarrow$ too early and too technical at this stage of the paper.} \\

On average, participants perform poorly in both treatments (see Figure \ref{fig:1}A), and improvement of the proposed models over time follows an extremely slow decay [with Jensen-Shannon Distance $D_{jsd}(t) \sim t^{\nu}$ with $ \nu \approx -0.15(1)$]. \\

{\bf [to be extended and refined as results converge:]} The experiment reveals fine grained mechanisms of how people struggle to balance recombination of mental structures stored in memory with exploration beyond their current cognitive frontier.  Our results suggest that displacement $0.1 < \Delta r < 0.2 $ is particularly beneficial for making progress toward the correct solution. We also find that large displacements seem to require orders of magnitude more ``cognitive processing'' time compared to small displacements. Displacement $0.1 < \Delta r < 0.2 $ is precisely at the inflexion point before waiting times get punishingly long.\\

{\bf [remants to be integrated elsewhere : ]} We first report on the experimental results, in particular deviations from a memoryless L\'evy Walks/Flights, such as peculiar returns to previously visited solutions, {\bf anomalous mean square displacement following return and recombination [more work is needed here]}, explorations beyond the cognitive frontier, as well as waiting-time and long-memory processes. What emerges from our observations is an empirically driven psychological theory of the cognitive costs of new ideas. These costs prevent optimality, as there is nothing special about the ideas that have already occurred, with respect to reality and the possibilities as to how things might actually work. It is important to note that there is a macro-parallel here with Thomas S. Kuhn's ``The Structure of Scientific Revolutions''--also, in a less direct and perhaps deeper level, to Stephen Jay Gould's theory of evolution by punctuated equilibria. Less direct only because Bayesian Nets are really quite like the ``scientific paradigms'' in Kuhn but they are only indirectly or metaphorically like evolutionary ``rugged fitness landscapes''. We then show how memory, exploration and recombination influence performance. {\bf Building on theoretical consideration in conjunction with observed stylized facts, we test a model of mechanics of cognition in situations in which people tackle hard problems [remains to be done. It may incorporate some Hawkes Processes, but not 100\% sure yet]}. 

This article is organized as follows. As for background, we first review (optimal) search processes in nature and society, and how they connect to causal inference {\bf [not sure if we can do that actually, because they processes are typically memoryless, and do not necessarily involve memory, exception made of [c.f. article in ipad]]}. We then present the specifics of the conducted experiment, and its results, including indications of (i) {\it an anomalous super-diffusive process},  (ii) the {\it exploit vs. explore} phenomenon, and (iii) {\it memory, return to previously visited sites \& recombination}, followed by the discussion. 





