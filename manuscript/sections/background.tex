\section{Background}


\subsection{Optimal Search in Nature and Society}

{\bf [to be filled by Thomas]}

\subsection{Cognitive mechanisms involved for solving hard problems}

%{\bf [ $\rightarrow$ this subsection needs proper citation and cognitive science lingo]}

When the objective is to estimate a high dimensional joint distribution on hand of lower dimensional, but complex structures, there is no unique solution, but the solution space is partitioned into classes of solutions known as equivalence classes. These equivalence classes are those sets of structural and parametric solutions that factor into the same joint distribution \cite{pearl2009causality, Pearl2009CMR, Koller2009PGM}. From an observational perspective, these lower dimensional models are thus equivalent. In other words, the processes that belong to the same equivalence class give, statistically, rise to the same observations.  Out of these equivalence classes, it is the objective to find the unique equivalence class to which the data generation process--that processes that has produced the observations--belongs. Note also that if there exists a {\it causal explanation} of the process, this explanation has the simplest structure in its equivalence class \cite{Koller2009PGM} and this simplest structure is unique. Cognitive scientists have postulated that the human concept of causation is a hard wired cognitive abstraction, used to explain observations by the simplest equivalent mechanism.  Since this process--even the structurally simplest member of its equivalence class--might be rather complex, it may be approached over time through iterative parametric refinements of a mental model of this process, as well as through sudden structural epiphanies. Yet getting close to this solution is hard because interdependencies often have unintuitive observational consequences, or rather, observations often result from  probabilistic influence that is unintuitive to humans. Human intuitive failure with respect to probabilistic influence and its logical consequences is best illustrated through the famous Monty Hall problem \cite{Blackburn08Phil, Honderich05Phil, Upton14Statistics, Colman08Psych}. \\

{\bf [This paragraph is great but it should be rewritten as a background paragraph, i.e., by engaging the literature, as much as possible]}. People tackling hard problems face a tension between testing and updating their beliefs from parameters and structures stored in their memory (i.e., {\it exploitation} or {\it recombination of mental structures}), and taking action to {\it explore} and update their beliefs from not previously available mental structure. Taking such action is cognitively equivalent to the exploration of unknown territories by pioneers in the physical world, or more directly, to scientists asking and then testing new hypotheses. The former {\it exploitation} approach may bring improvement toward the solution but it is limited to a {\bf convex combination} of previously tried solutions. The latter approach carries higher potential risks (behind the hill a leopard might be lurking, or research funds might be wasted on finding nothing of interest) as well as higher potential returns (there might be an unmeasurable treasure hidden behind the hill, or a cure for cancer might be found), but whether exploration brings improvement towards the solution at some given moment or not, this strategy expands the cognitive frontier. Below we refer to the convex hull of previously explored solutions as the {\it cognitive frontier}.  Once a new portion of the solution space has been explored, the attempted proposed model is then stored into memory and may be recombined, later on, with other proposed models, in proportion with its believed usefulness. \\

{\bf [This paragraph was commented out. Even though I know little of this, I thought it could be given a chance to be rewritten as part of the background section. If you think there is no value, please remove altogether.]} \textcolor{red}{
On average, especially when incentives are higher or tasks simple, subjects update their beliefs based on new data in a way that is consistent with Bayes rule.  This is demonstrated in numerous papers \cite{Griffiths2008}EXPLAIN + CITE EXPERIMENTS
However, at the individual level, there are large variations, as well as systematic departures under certain conditions. 
1) observed deviations from Bayesian learning
this can be organized by 
- "biases" in the priors (i.e. hypotheses), in particular deterministic bias
- deviations in the updating process: 
* representativeness heuristic/availability bias : tendency to overweight the strength of an observation and underweight its weight. Griffin and Tversky 1992 \cite{griffin1992weighing}; Holt and Smith 2009 \cite{holt2009update} ; Grether 1992 \cite{grether1992testing}. This is connected with the neglect of base rates (subjects overweigh the likelihood relative to the base rates/objective priors), and the resulting « law of small numbers » (over-generalizing from small number of observations), see Rabin 2002 \cite{rabin2002perspective}.
* ambiguous information is taken to be confirmation of current hypothesis, which is an obstacle to learning
- non-optimal acquisition of information/memory: recency bias, search for confirming evidence rather than disconfirmatory evidence (this last category is in my opinion not that relevant for your case) prediction: people have difficulties performing contingent reasoning on future events (Charness and Levin 2009 \cite{charness2009origin}). Additionally, Bayes rules makes no prediction about how learners should react to zero probability events, nor how learners should structure the hypothesis space when there are no objectively known base rates of events ad nlearners have to learn about the whole structure of the underlying environment, not just a few parameters (basically, in most natural environments, such as in markets). This is the situation explored by Ortoleva \cite{ortoleva2012modeling} and that is rarely examined in experimental settings  These departures are clues to the heuristics humans use in their judgments, which overall often approximate bayesian inference but are not equivalent. Although many of these deviations imply that learning should be slower than predicted by Bayes rule,  few experiments measure the rate of learning and how far it departs from Bayesian inference. We find that it does (slower). Furthermore, we also find that the quality of the inferences at each time space and across players varies a lot, following a "punctuated equilibrium" pattern. These observations are thus additional clues about the cognitive processes at play, with fine-grained information about how subjects update their beliefs in response to new information and the success and failure of their bets. Below were review some of the promising cognitive mechanisms posited to explain some of the deviations above and which can be evaluated in light of our data. 2) Cognitive mechanisms  Interesting mechanisms have to do with how people organize the hypothesis space and sample from it.  - sampling hypothesis - change of paradigm when observing "surprising events" (Ortoleva) \cite{ortoleva2012modeling} the satisficing principle may also mediate the learning process because computations such as Bayes rules are costly.
}

\subsection{Economic aspects of finding solutions to hard problems}

{\bf [ideally, there should be a section on this, to build upon]}
